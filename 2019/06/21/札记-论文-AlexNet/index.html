<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>札记_论文_AlexNet | Univesre</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="AlexNet的”官方”论文为ImageNet Classiﬁcation with Deep Convolutional Neural Networks [ref], 发表于2012(7年前, :)), 论文的三位作者分别是Alex(第一作者), Ilya和Geoffrey Hinton(前两位的导师), 其中的Dropout概念, 应当是很有影响的概念了. 此篇论文共7个章节, 下面我将论文的">
<meta name="keywords" content="Univesre">
<meta property="og:type" content="article">
<meta property="og:title" content="札记_论文_AlexNet">
<meta property="og:url" content="https://tjipot.github.io/2019/06/21/札记-论文-AlexNet/index.html">
<meta property="og:site_name" content="Univesre">
<meta property="og:description" content="AlexNet的”官方”论文为ImageNet Classiﬁcation with Deep Convolutional Neural Networks [ref], 发表于2012(7年前, :)), 论文的三位作者分别是Alex(第一作者), Ilya和Geoffrey Hinton(前两位的导师), 其中的Dropout概念, 应当是很有影响的概念了. 此篇论文共7个章节, 下面我将论文的">
<meta property="og:locale" content="Chinese">
<meta property="og:image" content="https://i.loli.net/2019/06/18/5d08e449496d242029.png">
<meta property="og:image" content="https://i.loli.net/2019/06/18/5d08e44a99ba510264.png">
<meta property="og:updated_time" content="2019-06-20T16:38:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="札记_论文_AlexNet">
<meta name="twitter:description" content="AlexNet的”官方”论文为ImageNet Classiﬁcation with Deep Convolutional Neural Networks [ref], 发表于2012(7年前, :)), 论文的三位作者分别是Alex(第一作者), Ilya和Geoffrey Hinton(前两位的导师), 其中的Dropout概念, 应当是很有影响的概念了. 此篇论文共7个章节, 下面我将论文的">
<meta name="twitter:image" content="https://i.loli.net/2019/06/18/5d08e449496d242029.png">
  
    <link rel="alternate" href="/atom.xml" title="Univesre" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Univesre</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Universe Is Not Univesre</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://tjipot.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-札记-论文-AlexNet" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/06/21/札记-论文-AlexNet/" class="article-date">
  <time datetime="2019-06-20T16:37:49.000Z" itemprop="datePublished">2019-06-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      札记_论文_AlexNet
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>AlexNet的”官方”论文为<strong><em>ImageNet Classiﬁcation with Deep Convolutional Neural Networks</em></strong> [<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networ" target="_blank" rel="noopener">ref</a>], 发表于2012(7年前, :)), 论文的三位作者分别是Alex(第一作者), Ilya和Geoffrey Hinton(前两位的导师), 其中的<strong>Dropout</strong>概念, 应当是很有影响的概念了.</p>
<p>此篇论文共7个章节, 下面我将论文的读后理解札记下来, 输出出来加深印象.</p>
<p>(Abstract)</p>
<ol>
<li>Introduction</li>
<li>The Dataset</li>
<li>The Architecture</li>
<li>Reducing Overfitting</li>
<li>Details of learning</li>
<li>Results</li>
<li>Discussion</li>
</ol>
<p>(Reference)<br><br><br></p>
<hr>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="(Abstract)"></a>(Abstract)</h4><p>概括了作者要提出的模型的一些简要情况: ILSVRC-2010的top-1和top-5的错误率为37.5%和17.0%的一个模型(比之前的都要好), 以及这个模型有6,000万个参数和6.5万个神经元. 该模型使用的一些技巧, 有: 5个卷积层(后接最大池化层)和3个全连接层(其中两个应用了Dropout), (为了加速训练)非饱和神经元(即ReLU)以及GPU的使用. 使用该模型的一个变化版本, 在ILSVRC-2012得到了15.3%的错误率(top-5).<br><br><br></p>
<hr>
<h4 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h4><p>该部分首先简述了小数据集(几万张的级别)的作用: 在简单的识别任务中(如MNIST数字识别), 这样的数据集可以适用和胜任. 然后, 说明了在真实环境中对象是会变化的(variability, 注: 如角度, 成像大小等), 引出我们需要更大的数据集的需求, 并提到了其中两个: LabelMe和ImageNet.</p>
<p>接着该部分的第二段, 提到了模型的学习能力(learning capacity, 学习什么?! 识别对象): 即便有了像ImageNet这样的大数据集, 由于对象识别任务的巨大复杂性(immense complexity, 没法靠人工去一一指定), 也不可能将对象识别这个任务明确指定好(具体如何识别对象). 继续, 文中提到CNN, 提及CNN的学习能力(匹配识别对象的复杂度)可由CNN模型的深度(depth)和广度(breadth)控制.</p>
<p>接下去的三段, 主要内容为: 1.CNN与GPU与数据, 2.论文的几点重要贡献罗列, 3.论文中网络的尺寸(受限于GPU内存与训练时间).<br><br><br></p>
<hr>
<h4 id="2-The-Dataset"><a href="#2-The-Dataset" class="headerlink" title="2.The Dataset"></a>2.The Dataset</h4><p>这一部分, 先是介绍了ImageNet(1,500万高分辨率图像, 22,000个类别), 而ILSVRC使用的是ImageNet的一个子集. 然后, 在下一段, 论文说明了测试集标签的问题: ILSVRC-2010是ILSVRC竞赛中唯一有测试集标签的版本(大多数实验都在此版本上进行), 论文中使用了top-1和top-5错误率作为报告的错误率.</p>
<p>最后一段, 讲述了论文处理图像分辨率的方式: 短边缩放至256的值, 并裁剪长边为256. 另外, 论文方法也对整个训练集的图片进行了”减去平均活跃值”(mean activity)的处理.<br><br><br></p>
<hr>
<h4 id="3-The-Architecture"><a href="#3-The-Architecture" class="headerlink" title="3.The Architecture"></a>3.The Architecture</h4><p>该部分主要讲述模型的架构(8个主要网络层 = 5个Conv + 3个FC), 以及网络中使用到的一些特性(ReLU, 多GPU训练等).</p>
<p>首先, 在3.1节ReLU Nonlinearity中, 论文对比了饱和非线性性(saturating nonlinearity, 如tanh函数)和非饱和非线性性(non-saturating nonlinearity, 此处的ReLU函数), 指出ReLU加快了网络的训练(图1).<br><img src="https://i.loli.net/2019/06/18/5d08e449496d242029.png" alt="AlexNet_Fig_01.png">{:height=”250”}</p>
<p>(图自: 论文 Figure 1)</p>
<p>其次, 在3.2节”Training on Multiple GPUs”中, 提到受限于GPU内存的大小(论文使用的GPU内存为3GB), 故将网络分布在两个GPU上进行训练, 此并行方案是: 基本上, 每个GPU放置一半的核; 另外, 在第3层时进行GPU间的通信: 第3层的核(分别在两个GPU中)会将第2层的所有feature map(两个GPU中所有的)同时作为输入进行卷积运算.</p>
<p>接下去, 论文的3.3节”Local Response Normalization”和3.4节”Overlapping Pooling”分别讲述了这两种技术(局部响应归一化, 重叠池化), 但现在这两种技巧并不被经常使用(?!).</p>
<p>最后, 3.5节”Overall Architecture”描述了AlexNet模型的总体架构, 为5个卷积层与3个全连接层的”一个序列”, 具体有如下图的结构:<br><img src="https://i.loli.net/2019/06/18/5d08e44a99ba510264.png" alt="AlexNet_Fig_02.png"></p>
<p>(图自: 论文 Figure 2)</p>
<p><br><br></p>
<hr>
<h4 id="4-Reducing-Overfitting"><a href="#4-Reducing-Overfitting" class="headerlink" title="4.Reducing Overfitting"></a>4.Reducing Overfitting</h4><p>在这一部分, 论文提及到了减小过拟合的两个主要方式(数据增强, Dropout), 这么做的原因是因为网络架构的参数有6,000万个(很多, 多于数据集的scale), 会产生过拟合.</p>
<p>在4.1节”Data Augmentation”中, 论文提及了两种数据增强的方式: 1.图像变换和水平翻转(裁剪出224x224的图像块), 2.改变训练集图像RGB通道的强度(对像素值集合执行PCA并对图像加上多倍找到的主成分).</p>
<p>在4.2节”Dropout”中, 论文介绍了这一概念, 以及它的应用位置: 在三个全连接层的前两层的输出中应用.<br><br><br></p>
<hr>
<h4 id="5-Details-of-learning"><a href="#5-Details-of-learning" class="headerlink" title="5.Details of learning"></a>5.Details of learning</h4><p>此部分具体讲述了论文模型的训练细节: 如参数设置, 参数初始化等. 在模型训练中, 论文团队使用了SGD(随机梯度下降, batch_size=128), 动量(=0.9), 权重衰减(=0.0005)等设置.<br><br><br></p>
<hr>
<h4 id="6-Results"><a href="#6-Results" class="headerlink" title="6.Results"></a>6.Results</h4><p>论文的神经网络在ILSVRC-2010数据集上的结果有top-1 37.5%和top-5 17.5%的表现, 这在当时(2012年及以前)来说, 是已公布结果中最好的(ILSVRC-2010竞赛的最佳结果是: top-1 47.1%, top-5 28.2%). 另外, 论文也涵盖了所涉模型在ILSVRC-2012竞赛(测试集标签不公开)中的结果.<br><br><br></p>
<hr>
<h4 id="7-Discussion"><a href="#7-Discussion" class="headerlink" title="7.Discussion"></a>7.Discussion</h4><p>讨论部分, 论文总述大型深度卷积神经网络(A large, deep convolutional neural network)可以取得的破纪录结果, 并佐证深度的重要性: 在论文的模型中, 移除任何中间层都会导致大约2%的top-1性能损失.</p>
<p>最后, 论文进行了一些模型之外的探讨.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://tjipot.github.io/2019/06/21/札记-论文-AlexNet/" data-id="cjx4w4tha000441zswh33wl7y" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/06/21/札记-TensorFlow-机制/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          札记_TensorFlow_机制
        
      </div>
    </a>
  
  
    <a href="/2019/06/21/札记-PYTHON/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">札记_PYTHON</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/06/21/札记-TensorFlow-机制/">札记_TensorFlow_机制</a>
          </li>
        
          <li>
            <a href="/2019/06/21/札记-论文-AlexNet/">札记_论文_AlexNet</a>
          </li>
        
          <li>
            <a href="/2019/06/21/札记-PYTHON/">札记_PYTHON</a>
          </li>
        
          <li>
            <a href="/2019/06/21/New-For-Hexo/">New_For_Hexo</a>
          </li>
        
          <li>
            <a href="/2019/06/20/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Haoran Ye<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>